{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0r/w8vqcgg56n9113ksf0mt1n940000gn/T/ipykernel_66711/836299164.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    root_mean_squared_error,\n",
    ")\n",
    "import yfinance as yf\n",
    "from constants import DATA_END_DATE, DATA_START_DATE\n",
    "from db_helper_functions import (\n",
    "    get_stock_news_with_finbert_tone_scores_from_db,\n",
    "    get_stock_news_with_finbert_whole_article_scores_from_db,\n",
    "    get_stock_news_with_finbert_scores_from_db,\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "from constants import SHARED_RANDOM_STATE\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    ")\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "ticker = \"AAPL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opts = [\n",
    "    get_stock_news_with_finbert_tone_scores_from_db(ticker),\n",
    "    get_stock_news_with_finbert_whole_article_scores_from_db(ticker),\n",
    "    get_stock_news_with_finbert_scores_from_db(ticker),\n",
    "]\n",
    "df = df_opts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sentiments = (\n",
    "    df.groupby(\"date\", as_index=False)\n",
    "    .agg({\"positive\": \"mean\", \"negative\": \"mean\", \"neutral\": \"mean\"})\n",
    "    .sort_values(by=\"date\", ascending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raulmartinez/Desktop/MADS/Milestone_2/w24-milestone2-team18-leevw-steveso-raulmart/.venv/lib/python3.11/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
     ]
    }
   ],
   "source": [
    "price_history = (\n",
    "    yf.Ticker(ticker).history(start=DATA_START_DATE, end=DATA_END_DATE).reset_index()\n",
    ")\n",
    "price_history.columns = [\"_\".join(x.lower().split(\" \")) for x in price_history.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_history[\"date\"] = price_history[\"date\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df = pd.merge(\n",
    "    price_history, grouped_sentiments, left_on=\"date\", right_on=\"date\", how=\"left\"\n",
    ")\n",
    "combo_df[\"date\"] = pd.to_datetime(combo_df[\"date\"])\n",
    "combo_df = combo_df.sort_values(by=\"date\", ascending=True)\n",
    "combo_df = combo_df.set_index(\"date\")\n",
    "combo_df[\"day_of_month\"] = combo_df.index.day\n",
    "combo_df[\"day_of_week\"] = combo_df.index.dayofweek\n",
    "combo_df[\"quarter\"] = combo_df.index.quarter\n",
    "combo_df[\"month\"] = combo_df.index.month\n",
    "combo_df[\"year\"] = combo_df.index.year\n",
    "combo_df[\"month_year\"] = combo_df.index.to_period(\"M\")\n",
    "combo_df[\"week_year\"] = combo_df.index.to_period(\"W\")\n",
    "combo_df[[\"positive\", \"negative\", \"neutral\"]] = combo_df[\n",
    "    [\"positive\", \"negative\", \"neutral\"]\n",
    "].ffill()\n",
    "combo_df[[\"positive\", \"negative\", \"neutral\"]] = combo_df[\n",
    "    [\"positive\", \"negative\", \"neutral\"]\n",
    "].shift(1)\n",
    "combo_df[[\"prev_high\", \"prev_low\", \"prev_close\", \"prev_volume\"]] = combo_df[\n",
    "    [\"high\", \"low\", \"close\", \"volume\"]\n",
    "].shift(1)\n",
    "combo_df = combo_df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv_model_search(models, grouped_df, predictive_feats, target_feat):\n",
    "    model_scores = []\n",
    "    for model, param_grid in models:\n",
    "        for params in ParameterGrid(param_grid):\n",
    "            model.set_params(**params)\n",
    "\n",
    "            count = 0\n",
    "            prev_grp = None\n",
    "            mse_scores = []\n",
    "            rmse_scores = []\n",
    "            mae_scores = []\n",
    "\n",
    "            for _idx, grp in grouped_df:\n",
    "                if count == 0:\n",
    "                    prev_grp = grp\n",
    "                    count += 1\n",
    "                    continue\n",
    "                train = prev_grp\n",
    "                test = grp\n",
    "\n",
    "                minmax_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "                X_train = train[predictive_feats]\n",
    "                X_train = minmax_scaler.fit_transform(X_train)\n",
    "                y_train = train[target_feat]\n",
    "\n",
    "                X_test = test[predictive_feats]\n",
    "                X_test = minmax_scaler.transform(X_test)\n",
    "                y_test = test[target_feat]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                pred = model.predict(X_test)\n",
    "\n",
    "                mse_scores.append(mean_squared_error(y_test, pred))\n",
    "                rmse_scores.append(root_mean_squared_error(y_test, pred))\n",
    "                mae_scores.append(mean_absolute_error(y_test, pred))\n",
    "\n",
    "                prev_grp = grp\n",
    "\n",
    "            model_scores.append(\n",
    "                (\n",
    "                    model,\n",
    "                    params,\n",
    "                    np.mean(mse_scores),\n",
    "                    np.mean(rmse_scores),\n",
    "                    np.mean(mae_scores),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(KNeighborsRegressor(n_neighbors=4),\n",
       "  {'n_neighbors': 3},\n",
       "  19.68476897247656,\n",
       "  3.5926739546057322,\n",
       "  3.2423378962736864),\n",
       " (KNeighborsRegressor(n_neighbors=4),\n",
       "  {'n_neighbors': 4},\n",
       "  19.88283872848489,\n",
       "  3.5949743646503616,\n",
       "  3.2498723064477626),\n",
       " (KNeighborsRegressor(n_neighbors=4),\n",
       "  {'n_neighbors': 2},\n",
       "  20.39861214420479,\n",
       "  3.65357756253946,\n",
       "  3.2715034379408907),\n",
       " (GradientBoostingRegressor(random_state=1337),\n",
       "  {'loss': 'absolute_error', 'random_state': 1337},\n",
       "  21.240638095584174,\n",
       "  3.7429363476819377,\n",
       "  3.3479008781823634),\n",
       " (GradientBoostingRegressor(random_state=1337),\n",
       "  {'loss': 'squared_error', 'random_state': 1337},\n",
       "  21.710846694260866,\n",
       "  3.800386792449836,\n",
       "  3.3641138831900914)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictive_features = [\n",
    "    # \"open\",\n",
    "    # \"prev_high\",\n",
    "    # \"prev_low\",\n",
    "    # \"prev_close\",\n",
    "    # \"prev_volume\",\n",
    "    # \"dividends\",\n",
    "    # \"stock_splits\",\n",
    "    \"positive\",\n",
    "    \"negative\",\n",
    "    \"neutral\",\n",
    "    # \"day_of_month\",\n",
    "    # \"day_of_week\",\n",
    "    # \"quarter\",\n",
    "    # \"month\",\n",
    "    # \"year\",\n",
    "]\n",
    "\n",
    "target_feat = \"close\"\n",
    "\n",
    "models_with_param_grids = [\n",
    "    (\n",
    "        GradientBoostingRegressor(),\n",
    "        {\n",
    "            \"random_state\": [SHARED_RANDOM_STATE],\n",
    "            \"loss\": [\"absolute_error\", \"squared_error\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        KNeighborsRegressor(),\n",
    "        {\n",
    "            \"n_neighbors\": [2, 3, 4],\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "results = time_series_cv_model_search(\n",
    "    models_with_param_grids,\n",
    "    combo_df.groupby(\"week_year\"),\n",
    "    predictive_features,\n",
    "    target_feat,\n",
    ")\n",
    "\n",
    "sorted(results, key=lambda x: x[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
