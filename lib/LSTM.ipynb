{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_23808\\1909415559.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yfinance as yf\n",
    "from constants import DATA_END_DATE, DATA_START_DATE\n",
    "from db_helper_functions import (\n",
    "    get_stock_news_with_finbert_tone_scores_from_db,\n",
    "    get_stock_news_with_finbert_whole_article_scores_from_db,\n",
    "    get_stock_news_with_finbert_scores_from_db,\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "ticker = \"AAPL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\yfinance\\utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock splits</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>34.636166</td>\n",
       "      <td>35.599548</td>\n",
       "      <td>34.461225</td>\n",
       "      <td>35.530048</td>\n",
       "      <td>234428400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358300</td>\n",
       "      <td>0.426100</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>35.635499</td>\n",
       "      <td>35.666654</td>\n",
       "      <td>34.964487</td>\n",
       "      <td>35.450970</td>\n",
       "      <td>219111200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.196400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>35.841597</td>\n",
       "      <td>36.383202</td>\n",
       "      <td>35.592366</td>\n",
       "      <td>36.126778</td>\n",
       "      <td>164101200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.531600</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09</th>\n",
       "      <td>36.256181</td>\n",
       "      <td>37.032638</td>\n",
       "      <td>35.858370</td>\n",
       "      <td>36.740269</td>\n",
       "      <td>180396400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268725</td>\n",
       "      <td>0.414900</td>\n",
       "      <td>0.316400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-10</th>\n",
       "      <td>36.546147</td>\n",
       "      <td>36.898428</td>\n",
       "      <td>36.153127</td>\n",
       "      <td>36.857689</td>\n",
       "      <td>143122800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405500</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>130.483247</td>\n",
       "      <td>130.513041</td>\n",
       "      <td>127.841400</td>\n",
       "      <td>129.142456</td>\n",
       "      <td>69007800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236418</td>\n",
       "      <td>0.375418</td>\n",
       "      <td>0.388145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>128.784900</td>\n",
       "      <td>130.135617</td>\n",
       "      <td>125.010842</td>\n",
       "      <td>125.179680</td>\n",
       "      <td>85438400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180425</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.395763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>127.116381</td>\n",
       "      <td>129.589383</td>\n",
       "      <td>126.858162</td>\n",
       "      <td>128.725327</td>\n",
       "      <td>75703700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292311</td>\n",
       "      <td>0.475433</td>\n",
       "      <td>0.232256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>127.533507</td>\n",
       "      <td>129.062989</td>\n",
       "      <td>126.560193</td>\n",
       "      <td>129.043121</td>\n",
       "      <td>77034200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382640</td>\n",
       "      <td>0.364780</td>\n",
       "      <td>0.252600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>129.390738</td>\n",
       "      <td>130.006501</td>\n",
       "      <td>123.322443</td>\n",
       "      <td>124.216301</td>\n",
       "      <td>112117500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316200</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>0.241600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1007 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close     volume  \\\n",
       "date                                                                    \n",
       "2019-01-04   34.636166   35.599548   34.461225   35.530048  234428400   \n",
       "2019-01-07   35.635499   35.666654   34.964487   35.450970  219111200   \n",
       "2019-01-08   35.841597   36.383202   35.592366   36.126778  164101200   \n",
       "2019-01-09   36.256181   37.032638   35.858370   36.740269  180396400   \n",
       "2019-01-10   36.546147   36.898428   36.153127   36.857689  143122800   \n",
       "...                ...         ...         ...         ...        ...   \n",
       "2022-12-27  130.483247  130.513041  127.841400  129.142456   69007800   \n",
       "2022-12-28  128.784900  130.135617  125.010842  125.179680   85438400   \n",
       "2022-12-29  127.116381  129.589383  126.858162  128.725327   75703700   \n",
       "2022-12-30  127.533507  129.062989  126.560193  129.043121   77034200   \n",
       "2023-01-03  129.390738  130.006501  123.322443  124.216301  112117500   \n",
       "\n",
       "            dividends  stock splits  positive  negative   neutral  \n",
       "date                                                               \n",
       "2019-01-04        0.0           0.0  0.358300  0.426100  0.215600  \n",
       "2019-01-07        0.0           0.0  0.117100  0.686500  0.196400  \n",
       "2019-01-08        0.0           0.0  0.252700  0.531600  0.215600  \n",
       "2019-01-09        0.0           0.0  0.268725  0.414900  0.316400  \n",
       "2019-01-10        0.0           0.0  0.405500  0.202000  0.392500  \n",
       "...               ...           ...       ...       ...       ...  \n",
       "2022-12-27        0.0           0.0  0.236418  0.375418  0.388145  \n",
       "2022-12-28        0.0           0.0  0.180425  0.423800  0.395763  \n",
       "2022-12-29        0.0           0.0  0.292311  0.475433  0.232256  \n",
       "2022-12-30        0.0           0.0  0.382640  0.364780  0.252600  \n",
       "2023-01-03        0.0           0.0  0.316200  0.442211  0.241600  \n",
       "\n",
       "[1007 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_opts = [\n",
    "    get_stock_news_with_finbert_tone_scores_from_db(ticker),\n",
    "    get_stock_news_with_finbert_whole_article_scores_from_db(ticker),\n",
    "    get_stock_news_with_finbert_scores_from_db(ticker),\n",
    "]\n",
    "df = df_opts[1]\n",
    "grouped_sentiments = df.groupby(\"date\", as_index=False).agg(\n",
    "    {\"positive\": \"mean\", \"negative\": \"mean\", \"neutral\": \"mean\"}\n",
    ")\n",
    "price_history = (\n",
    "    yf.Ticker(ticker).history(start=DATA_START_DATE, end=DATA_END_DATE).reset_index()\n",
    ")\n",
    "price_history.columns = [x.lower() for x in price_history.columns]\n",
    "price_history[\"date\"] = price_history[\"date\"].dt.date\n",
    "price_history.head()\n",
    "combo_df = pd.merge(\n",
    "    price_history, grouped_sentiments, left_on=\"date\", right_on=\"date\", how=\"left\"\n",
    ")\n",
    "combo_df = combo_df.sort_values(by=\"date\", ascending=True)\n",
    "combo_df = combo_df.set_index(\"date\")\n",
    "combo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from torch import nn, torch\n",
    "from torch.nn import LSTM\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_monthly</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01</th>\n",
       "      <td>37.049162</td>\n",
       "      <td>0.291351</td>\n",
       "      <td>0.399724</td>\n",
       "      <td>0.308912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02</th>\n",
       "      <td>41.284198</td>\n",
       "      <td>0.305565</td>\n",
       "      <td>0.350038</td>\n",
       "      <td>0.344378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03</th>\n",
       "      <td>44.114185</td>\n",
       "      <td>0.286235</td>\n",
       "      <td>0.269212</td>\n",
       "      <td>0.444551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04</th>\n",
       "      <td>48.259177</td>\n",
       "      <td>0.339818</td>\n",
       "      <td>0.350140</td>\n",
       "      <td>0.310044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05</th>\n",
       "      <td>46.151072</td>\n",
       "      <td>0.275238</td>\n",
       "      <td>0.367214</td>\n",
       "      <td>0.357551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09</th>\n",
       "      <td>151.706829</td>\n",
       "      <td>0.221570</td>\n",
       "      <td>0.393089</td>\n",
       "      <td>0.385339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10</th>\n",
       "      <td>143.784985</td>\n",
       "      <td>0.244999</td>\n",
       "      <td>0.371511</td>\n",
       "      <td>0.383489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11</th>\n",
       "      <td>144.813804</td>\n",
       "      <td>0.236016</td>\n",
       "      <td>0.361605</td>\n",
       "      <td>0.402381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12</th>\n",
       "      <td>136.935554</td>\n",
       "      <td>0.253168</td>\n",
       "      <td>0.355630</td>\n",
       "      <td>0.391191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01</th>\n",
       "      <td>124.216301</td>\n",
       "      <td>0.316200</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>0.241600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   close  positive  negative   neutral\n",
       "date_monthly                                          \n",
       "2019-01        37.049162  0.291351  0.399724  0.308912\n",
       "2019-02        41.284198  0.305565  0.350038  0.344378\n",
       "2019-03        44.114185  0.286235  0.269212  0.444551\n",
       "2019-04        48.259177  0.339818  0.350140  0.310044\n",
       "2019-05        46.151072  0.275238  0.367214  0.357551\n",
       "...                  ...       ...       ...       ...\n",
       "2022-09       151.706829  0.221570  0.393089  0.385339\n",
       "2022-10       143.784985  0.244999  0.371511  0.383489\n",
       "2022-11       144.813804  0.236016  0.361605  0.402381\n",
       "2022-12       136.935554  0.253168  0.355630  0.391191\n",
       "2023-01       124.216301  0.316200  0.442211  0.241600\n",
       "\n",
       "[49 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_df = combo_df[['close', 'positive', 'negative', 'neutral']]\n",
    "\n",
    "# Aggregate data into months, using the average of columns as the values (ignoring NaN)\n",
    "def aggregate_monthly_data(df):\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df['date_monthly'] = df.index.to_period('M').strftime('%Y-%m')\n",
    "    monthly_data = df.groupby('date_monthly').mean()\n",
    "    monthly_data = monthly_data.sort_index()\n",
    "    return monthly_data\n",
    "monthly_df = aggregate_monthly_data(sentiments_df.copy())\n",
    "pd.set_option('display.max_rows', 10)\n",
    "monthly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/48, Train Loss: 0.0004\n",
      "Predicted Close: 37.01704025268555\n",
      "Actual Close: tensor([37.0492])\n",
      "Epoch: 1/48, Test Loss: 0.0019\n",
      "Epoch: 2/48, Train Loss: 0.0004\n",
      "Predicted Close: 41.253173828125\n",
      "Actual Close: tensor([41.2842])\n",
      "Epoch: 2/48, Test Loss: 0.0019\n",
      "Epoch: 3/48, Train Loss: 0.0003\n",
      "Predicted Close: 44.08424758911133\n",
      "Actual Close: tensor([44.1142])\n",
      "Epoch: 3/48, Test Loss: 0.0019\n",
      "Epoch: 4/48, Train Loss: 0.0003\n",
      "Predicted Close: 48.23017883300781\n",
      "Actual Close: tensor([48.2592])\n",
      "Epoch: 4/48, Test Loss: 0.0018\n",
      "Epoch: 5/48, Train Loss: 0.0003\n",
      "Predicted Close: 46.12311553955078\n",
      "Actual Close: tensor([46.1511])\n",
      "Epoch: 5/48, Test Loss: 0.0018\n",
      "Epoch: 6/48, Train Loss: 0.0003\n",
      "Predicted Close: 46.59474563598633\n",
      "Actual Close: tensor([46.6216])\n",
      "Epoch: 6/48, Test Loss: 0.0018\n",
      "Epoch: 7/48, Train Loss: 0.0002\n",
      "Predicted Close: 49.554725646972656\n",
      "Actual Close: tensor([49.5806])\n",
      "Epoch: 7/48, Test Loss: 0.0018\n",
      "Epoch: 8/48, Train Loss: 0.0002\n",
      "Predicted Close: 49.63116455078125\n",
      "Actual Close: tensor([49.6560])\n",
      "Epoch: 8/48, Test Loss: 0.0019\n",
      "Epoch: 9/48, Train Loss: 0.0002\n",
      "Predicted Close: 52.84434127807617\n",
      "Actual Close: tensor([52.8680])\n",
      "Epoch: 9/48, Test Loss: 0.0019\n",
      "Epoch: 10/48, Train Loss: 0.0002\n",
      "Predicted Close: 57.038917541503906\n",
      "Actual Close: tensor([57.0616])\n",
      "Epoch: 10/48, Test Loss: 0.0020\n",
      "Epoch: 11/48, Train Loss: 0.0002\n",
      "Predicted Close: 63.79851150512695\n",
      "Actual Close: tensor([63.8201])\n",
      "Epoch: 11/48, Test Loss: 0.0020\n",
      "Epoch: 12/48, Train Loss: 0.0001\n",
      "Predicted Close: 67.24374389648438\n",
      "Actual Close: tensor([67.2642])\n",
      "Epoch: 12/48, Test Loss: 0.0020\n",
      "Epoch: 13/48, Train Loss: 0.0001\n",
      "Predicted Close: 75.85344696044922\n",
      "Actual Close: tensor([75.8729])\n",
      "Epoch: 13/48, Test Loss: 0.0020\n",
      "Epoch: 14/48, Train Loss: 0.0001\n",
      "Predicted Close: 75.83844757080078\n",
      "Actual Close: tensor([75.8568])\n",
      "Epoch: 14/48, Test Loss: 0.0020\n",
      "Epoch: 15/48, Train Loss: 0.0001\n",
      "Predicted Close: 63.97310256958008\n",
      "Actual Close: tensor([63.9904])\n",
      "Epoch: 15/48, Test Loss: 0.0020\n",
      "Epoch: 16/48, Train Loss: 0.0001\n",
      "Predicted Close: 66.39834594726562\n",
      "Actual Close: tensor([66.4145])\n",
      "Epoch: 16/48, Test Loss: 0.0021\n",
      "Epoch: 17/48, Train Loss: 0.0001\n",
      "Predicted Close: 75.72270965576172\n",
      "Actual Close: tensor([75.7378])\n",
      "Epoch: 17/48, Test Loss: 0.0021\n",
      "Epoch: 18/48, Train Loss: 0.0001\n",
      "Predicted Close: 84.5304183959961\n",
      "Actual Close: tensor([84.5444])\n",
      "Epoch: 18/48, Test Loss: 0.0022\n",
      "Epoch: 19/48, Train Loss: 0.0001\n",
      "Predicted Close: 93.44507598876953\n",
      "Actual Close: tensor([93.4580])\n",
      "Epoch: 19/48, Test Loss: 0.0023\n",
      "Epoch: 20/48, Train Loss: 0.0001\n",
      "Predicted Close: 114.86985778808594\n",
      "Actual Close: tensor([114.8818])\n",
      "Epoch: 20/48, Test Loss: 0.0023\n",
      "Epoch: 21/48, Train Loss: 0.0000\n",
      "Predicted Close: 112.7776107788086\n",
      "Actual Close: tensor([112.7885])\n",
      "Epoch: 21/48, Test Loss: 0.0023\n",
      "Epoch: 22/48, Train Loss: 0.0000\n",
      "Predicted Close: 114.04047393798828\n",
      "Actual Close: tensor([114.0503])\n",
      "Epoch: 22/48, Test Loss: 0.0023\n",
      "Epoch: 23/48, Train Loss: 0.0000\n",
      "Predicted Close: 114.60504150390625\n",
      "Actual Close: tensor([114.6139])\n",
      "Epoch: 23/48, Test Loss: 0.0023\n",
      "Epoch: 24/48, Train Loss: 0.0000\n",
      "Predicted Close: 124.9140853881836\n",
      "Actual Close: tensor([124.9220])\n",
      "Epoch: 24/48, Test Loss: 0.0023\n",
      "Epoch: 25/48, Train Loss: 0.0000\n",
      "Predicted Close: 130.5544891357422\n",
      "Actual Close: tensor([130.5615])\n",
      "Epoch: 25/48, Test Loss: 0.0023\n",
      "Epoch: 26/48, Train Loss: 0.0000\n",
      "Predicted Close: 129.22933959960938\n",
      "Actual Close: tensor([129.2354])\n",
      "Epoch: 26/48, Test Loss: 0.0023\n",
      "Epoch: 27/48, Train Loss: 0.0000\n",
      "Predicted Close: 119.7772216796875\n",
      "Actual Close: tensor([119.7824])\n",
      "Epoch: 27/48, Test Loss: 0.0023\n",
      "Epoch: 28/48, Train Loss: 0.0000\n",
      "Predicted Close: 129.54920959472656\n",
      "Actual Close: tensor([129.5536])\n",
      "Epoch: 28/48, Test Loss: 0.0023\n",
      "Epoch: 29/48, Train Loss: 0.0000\n",
      "Predicted Close: 124.77571868896484\n",
      "Actual Close: tensor([124.7793])\n",
      "Epoch: 29/48, Test Loss: 0.0023\n",
      "Epoch: 30/48, Train Loss: 0.0000\n",
      "Predicted Close: 127.94523620605469\n",
      "Actual Close: tensor([127.9481])\n",
      "Epoch: 30/48, Test Loss: 0.0023\n",
      "Epoch: 31/48, Train Loss: 0.0000\n",
      "Predicted Close: 142.89198303222656\n",
      "Actual Close: tensor([142.8941])\n",
      "Epoch: 31/48, Test Loss: 0.0023\n",
      "Epoch: 32/48, Train Loss: 0.0000\n",
      "Predicted Close: 146.06304931640625\n",
      "Actual Close: tensor([146.0645])\n",
      "Epoch: 32/48, Test Loss: 0.0023\n",
      "Epoch: 33/48, Train Loss: 0.0000\n",
      "Predicted Close: 146.22962951660156\n",
      "Actual Close: tensor([146.2305])\n",
      "Epoch: 33/48, Test Loss: 0.0023\n",
      "Epoch: 34/48, Train Loss: 0.0000\n",
      "Predicted Close: 143.5261993408203\n",
      "Actual Close: tensor([143.5265])\n",
      "Epoch: 34/48, Test Loss: 0.0023\n",
      "Epoch: 35/48, Train Loss: 0.0000\n",
      "Predicted Close: 152.27774047851562\n",
      "Actual Close: tensor([152.2776])\n",
      "Epoch: 35/48, Test Loss: 0.0023\n",
      "Epoch: 36/48, Train Loss: 0.0000\n",
      "Predicted Close: 171.3740692138672\n",
      "Actual Close: tensor([171.3735])\n",
      "Epoch: 36/48, Test Loss: 0.0023\n",
      "Epoch: 37/48, Train Loss: 0.0000\n",
      "Predicted Close: 167.72958374023438\n",
      "Actual Close: tensor([167.7286])\n",
      "Epoch: 37/48, Test Loss: 0.0023\n",
      "Epoch: 38/48, Train Loss: 0.0000\n",
      "Predicted Close: 167.87777709960938\n",
      "Actual Close: tensor([167.8765])\n",
      "Epoch: 38/48, Test Loss: 0.0023\n",
      "Epoch: 39/48, Train Loss: 0.0000\n",
      "Predicted Close: 163.4442138671875\n",
      "Actual Close: tensor([163.4427])\n",
      "Epoch: 39/48, Test Loss: 0.0023\n",
      "Epoch: 40/48, Train Loss: 0.0000\n",
      "Predicted Close: 164.9379425048828\n",
      "Actual Close: tensor([164.9362])\n",
      "Epoch: 40/48, Test Loss: 0.0023\n",
      "Epoch: 41/48, Train Loss: 0.0000\n",
      "Predicted Close: 146.92672729492188\n",
      "Actual Close: tensor([146.9247])\n",
      "Epoch: 41/48, Test Loss: 0.0023\n",
      "Epoch: 42/48, Train Loss: 0.0000\n",
      "Predicted Close: 138.42425537109375\n",
      "Actual Close: tensor([138.4221])\n",
      "Epoch: 42/48, Test Loss: 0.0023\n",
      "Epoch: 43/48, Train Loss: 0.0000\n",
      "Predicted Close: 148.19908142089844\n",
      "Actual Close: tensor([148.1969])\n",
      "Epoch: 43/48, Test Loss: 0.0024\n",
      "Epoch: 44/48, Train Loss: 0.0000\n",
      "Predicted Close: 165.43482971191406\n",
      "Actual Close: tensor([165.4325])\n",
      "Epoch: 44/48, Test Loss: 0.0023\n",
      "Epoch: 45/48, Train Loss: 0.0000\n",
      "Predicted Close: 151.70913696289062\n",
      "Actual Close: tensor([151.7068])\n",
      "Epoch: 45/48, Test Loss: 0.0023\n",
      "Epoch: 46/48, Train Loss: 0.0000\n",
      "Predicted Close: 143.7873077392578\n",
      "Actual Close: tensor([143.7850])\n",
      "Epoch: 46/48, Test Loss: 0.0023\n",
      "Epoch: 47/48, Train Loss: 0.0000\n",
      "Predicted Close: 144.81607055664062\n",
      "Actual Close: tensor([144.8138])\n",
      "Epoch: 47/48, Test Loss: 0.0023\n",
      "Epoch: 48/48, Train Loss: 0.0000\n",
      "Predicted Close: 136.93777465820312\n",
      "Actual Close: tensor([136.9355])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\vince\\MADS\\Milestone 2\\w24-milestone2-team18-leevw-steveso-raulmart\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "train_data = monthly_df\n",
    "predictors = ['positive', 'negative', 'neutral']\n",
    "\n",
    "model = LSTM(len(predictors), 64, 2, batch_first=True)  # Input size is the length of predictors\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = MSELoss()\n",
    "\n",
    "for start_idx in range(len(monthly_df) - 1):\n",
    "    train_window = monthly_df.iloc[start_idx:start_idx+1][predictors + ['close']]\n",
    "    test_window = monthly_df.iloc[start_idx+1:start_idx+2][['close']]  # Use only the 'close' value for comparison\n",
    "\n",
    "    train_features = torch.from_numpy(train_window[predictors].values).float()\n",
    "    train_close = torch.tensor(train_window['close'].values).float()\n",
    "\n",
    "    # Train on the window\n",
    "    output, _ = model(train_features.unsqueeze(0))\n",
    "    train_close_predicted = train_close + output.squeeze()\n",
    "\n",
    "    # Compute training loss\n",
    "    loss = loss_fn(train_close_predicted, train_close)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {start_idx+1}/{len(monthly_df)-1}, Train Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Print predicted and actual closing prices\n",
    "    print(\"Predicted Close:\", train_close_predicted[0].item())\n",
    "    print(\"Actual Close:\", train_close)\n",
    "\n",
    "    if start_idx < len(monthly_df) - 2:\n",
    "        # Evaluate on the test set (separate from the training data)\n",
    "        test_close = torch.tensor(test_window['close'].values).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_output, _ = model(test_close.unsqueeze(0))  # Get the output tensor from the model\n",
    "            test_close_predicted = test_output.squeeze() + test_window['close'].values  # Predict the next month's closing price\n",
    "            \n",
    "            test_loss = loss_fn(test_close_predicted, test_close)\n",
    "            print(f\"Epoch: {start_idx+1}/{len(monthly_df)-1}, Test Loss: {test_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LSTM(len(predictors), 64, 2, batch_first=True)  # Input size is the length of predictors\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# loss_fn = MSELoss()\n",
    "\n",
    "# for start_idx in range(len(monthly_df) - 1):  # Adjust the range to prevent index out of bounds\n",
    "#     # Define training and testing windows based on datetime index\n",
    "#     train_window = monthly_df.iloc[start_idx:start_idx+1][predictors + ['close']]\n",
    "#     test_window = monthly_df.iloc[start_idx+1:start_idx+2][['close']]  # Use only the 'close' value for comparison\n",
    "\n",
    "#     # Convert to tensors\n",
    "#     train_features = torch.from_numpy(train_window[predictors].values).float()\n",
    "#     train_close = torch.tensor(train_window['close'].values).float()\n",
    "#     test_close = torch.tensor(test_window['close'].values).float()\n",
    "\n",
    "#     # Train on the window\n",
    "#     output, _ = model(train_features.unsqueeze(0))  # Add an extra dimension for batch size\n",
    "    \n",
    "#     # Extract the predicted value\n",
    "#     predicted_value = output.squeeze()  # Remove the batch dimension\n",
    "#     train_close_predicted = train_close + predicted_value  # Add the predicted value to the train month's close\n",
    "\n",
    "#     # Compute loss based on the comparison of the predicted close and the test close\n",
    "#     loss = loss_fn(train_close_predicted, test_close)\n",
    "#     print(train_close_predicted)\n",
    "#     print(test_close)\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     # Evaluate the test loss\n",
    "#     with torch.no_grad():\n",
    "#         test_output, _ = model(train_features.unsqueeze(0))  # Assuming you're evaluating on training data for simplicity\n",
    "#         test_predicted_value = test_output.squeeze()  # Remove the batch dimension\n",
    "#         test_close_predicted = train_close + test_predicted_value  # Add the predicted value to the train month's close\n",
    "    \n",
    "#     # Ensure that the shapes of test_close_predicted and test_close match\n",
    "#         if test_close_predicted.shape != test_close.shape:\n",
    "#             # Reshape or broadcast test_close_predicted to match the shape of test_close\n",
    "#             test_close_predicted = test_close_predicted.squeeze().unsqueeze(0)  # Adjust the shape as needed\n",
    "\n",
    "#         # Compute the test loss\n",
    "#         test_loss = loss_fn(test_close_predicted, test_close)\n",
    "\n",
    "#     # Print training and test progress\n",
    "#     print(f\"Epoch: {start_idx+1}/{len(monthly_df)-1}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
