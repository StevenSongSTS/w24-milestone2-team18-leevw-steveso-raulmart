{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from db_helper_functions import get_stock_news_from_db\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, MiniBatchNMF\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from bertopic import BERTopic\n",
    "from finbert_embedding.embedding import FinbertEmbedding\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>article</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4235</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Microsoft, Alphabet, Meta, Apple, And Amazon L...</td>\n",
       "      <td>https://www.benzinga.com/news/earnings/22/07/2...</td>\n",
       "      <td>(Monday Market Open) Investors appear optimist...</td>\n",
       "      <td>2022-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4376</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Benzinga Before The Bell: More Amazon Workers ...</td>\n",
       "      <td>https://www.benzinga.com/news/22/08/28532545/b...</td>\n",
       "      <td>CNBCBlackRock To Pledge A$1B In Australian Bat...</td>\n",
       "      <td>2022-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Market Rebounds On Trade Optimism, Tech Bounce...</td>\n",
       "      <td>https://www.benzinga.com/node/12934767</td>\n",
       "      <td>A stronger-than-expected government report on ...</td>\n",
       "      <td>2019-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>American Shippers And Carriers React To Signs ...</td>\n",
       "      <td>https://www.benzinga.com/node/12938837</td>\n",
       "      <td>The first week of 2019 saw three of America's ...</td>\n",
       "      <td>2019-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>TD Ameritrade IMX Continued Its Dip In Decembe...</td>\n",
       "      <td>https://www.benzinga.com/node/12953011</td>\n",
       "      <td>Declining for the third month in a row, TD Ame...</td>\n",
       "      <td>2019-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple CEO Tim Cook Talks With Jim Cramer—Here ...</td>\n",
       "      <td>https://www.benzinga.com/node/12957963</td>\n",
       "      <td>Apple Inc. AAPL CEO Tim Cook spoke with CNBC's...</td>\n",
       "      <td>2019-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Watching The Clock: Trade Talks End With Optim...</td>\n",
       "      <td>https://www.benzinga.com/node/12958812</td>\n",
       "      <td>Trade talks are over for this week, and now it...</td>\n",
       "      <td>2019-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>TD Ameritrade's Investor Movement Index Highli...</td>\n",
       "      <td>https://www.benzinga.com/node/12960171</td>\n",
       "      <td>Few investors would argue 2018 was a good year...</td>\n",
       "      <td>2019-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Stung By Poor Fiscal Q2 Print, FedEx Executive...</td>\n",
       "      <td>https://www.benzinga.com/node/12968719</td>\n",
       "      <td>Top FedEx Corp. FDX executives met with securi...</td>\n",
       "      <td>2019-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Another Day, Another Bank Misses On Earnings: ...</td>\n",
       "      <td>https://www.benzinga.com/node/12986104</td>\n",
       "      <td>Big bank earnings might get overshadowed a bit...</td>\n",
       "      <td>2019-01-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id ticker                                              title  \\\n",
       "0  4235   AAPL  Microsoft, Alphabet, Meta, Apple, And Amazon L...   \n",
       "1  4376   AAPL  Benzinga Before The Bell: More Amazon Workers ...   \n",
       "2     3   AAPL  Market Rebounds On Trade Optimism, Tech Bounce...   \n",
       "3     4   AAPL  American Shippers And Carriers React To Signs ...   \n",
       "4     5   AAPL  TD Ameritrade IMX Continued Its Dip In Decembe...   \n",
       "5     6   AAPL  Apple CEO Tim Cook Talks With Jim Cramer—Here ...   \n",
       "6     7   AAPL  Watching The Clock: Trade Talks End With Optim...   \n",
       "7     9   AAPL  TD Ameritrade's Investor Movement Index Highli...   \n",
       "8    10   AAPL  Stung By Poor Fiscal Q2 Print, FedEx Executive...   \n",
       "9    11   AAPL  Another Day, Another Bank Misses On Earnings: ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.benzinga.com/news/earnings/22/07/2...   \n",
       "1  https://www.benzinga.com/news/22/08/28532545/b...   \n",
       "2             https://www.benzinga.com/node/12934767   \n",
       "3             https://www.benzinga.com/node/12938837   \n",
       "4             https://www.benzinga.com/node/12953011   \n",
       "5             https://www.benzinga.com/node/12957963   \n",
       "6             https://www.benzinga.com/node/12958812   \n",
       "7             https://www.benzinga.com/node/12960171   \n",
       "8             https://www.benzinga.com/node/12968719   \n",
       "9             https://www.benzinga.com/node/12986104   \n",
       "\n",
       "                                             article        date  \n",
       "0  (Monday Market Open) Investors appear optimist...  2022-07-25  \n",
       "1  CNBCBlackRock To Pledge A$1B In Australian Bat...  2022-08-17  \n",
       "2  A stronger-than-expected government report on ...  2019-01-04  \n",
       "3  The first week of 2019 saw three of America's ...  2019-01-07  \n",
       "4  Declining for the third month in a row, TD Ame...  2019-01-08  \n",
       "5  Apple Inc. AAPL CEO Tim Cook spoke with CNBC's...  2019-01-09  \n",
       "6  Trade talks are over for this week, and now it...  2019-01-09  \n",
       "7  Few investors would argue 2018 was a good year...  2019-01-09  \n",
       "8  Top FedEx Corp. FDX executives met with securi...  2019-01-10  \n",
       "9  Big bank earnings might get overshadowed a bit...  2019-01-15  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_stock_news_from_db(\"AAPL\")\n",
    "df = df[~df.article.isnull()]\n",
    "t_df = df.iloc[:10]\n",
    "t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_end_of_articles = [x[-512:] for x in t_df.article]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert_mat = finbert_tokenizer(only_end_of_articles, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.1004, -0.9528,  2.6073],\n",
       "        [-0.3714, -1.7940,  2.4050],\n",
       "        [-0.6886, -1.4726,  2.4825],\n",
       "        [ 0.4505, -1.5235,  1.0758],\n",
       "        [-1.1281, -0.4418,  2.0902],\n",
       "        [-0.0192, -1.8209,  1.9907],\n",
       "        [-0.9612, -1.1091,  2.4879],\n",
       "        [-0.3719, -1.4385,  2.0067],\n",
       "        [-1.5400,  1.9244,  0.4078],\n",
       "        [-1.0008, -1.1154,  2.5392]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = finbert_model(**finbert_mat)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.023300036787986755, 0.027004476636648178, 0.9496954679489136],\n",
       " [0.05779491364955902, 0.013933811336755753, 0.9282712340354919],\n",
       " [0.03954237699508667, 0.0180546585470438, 0.9424030184745789],\n",
       " [0.33248171210289, 0.04618183523416519, 0.6213364005088806],\n",
       " [0.035750437527894974, 0.07101218402385712, 0.8932373523712158],\n",
       " [0.11590597033500671, 0.019126292318105698, 0.8649677634239197],\n",
       " [0.029998810961842537, 0.025873176753520966, 0.9441280364990234],\n",
       " [0.08240769058465958, 0.02836253121495247, 0.8892297744750977],\n",
       " [0.025017259642481804, 0.7995222806930542, 0.17546039819717407],\n",
       " [0.02750471979379654, 0.024526527151465416, 0.9479687809944153]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mt_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpositive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnegative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneutral\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m predictions\n",
      "File \u001b[0;32m~/Desktop/w24-milestone2-team18-leevw-steveso-raulmart/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4287\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[1;32m   4286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[0;32m-> 4287\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   4289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[0;32m~/Desktop/w24-milestone2-team18-leevw-steveso-raulmart/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4342\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_not_inplace(key, value)\n\u001b[1;32m   4340\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4341\u001b[0m     \u001b[38;5;66;03m# list of lists\u001b[39;00m\n\u001b[0;32m-> 4342\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m   4343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[1;32m   4345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/w24-milestone2-team18-leevw-steveso-raulmart/.venv/lib/python3.11/site-packages/pandas/core/frame.py:830\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, abc\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    829\u001b[0m         \u001b[38;5;66;03m# GH#44616 big perf improvement for e.g. pytorch tensor\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n",
      "File \u001b[0;32m~/Desktop/w24-milestone2-team18-leevw-steveso-raulmart/.venv/lib/python3.11/site-packages/torch/_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "t_df[[\"positive\", \"negative\", \"neutral\"]] = predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
